setwd("~/DataVisualization/DV_TProject1/01 Data")
require(tidyr)
require(dplyr)
require(ggplot2)
setwd("~/DataVisualization/DV_TProject1/01 Data")
file_path <- "StormEvents_details-ftp_v1.0_d2015_c20151021"
df <- read.csv(file_path, stringsAsFactors = FALSE)
require(tidyr)
require(dplyr)
require(ggplot2)
setwd("~/DataVisualization/DV_TProject1/01 Data")
file_path <- "StormEvents_details-ftp_v1.0_d2015_c20151021.csv"
df <- read.csv(file_path, stringsAsFactors = FALSE)
head(df)
dplyr::sample_n(df, 10000, replace = TRUE)
df <- sample_n(df, 10000, replace = TRUE)
write.csv(df, paste(gsub(".csv", "", file_path), "10k", sep=""), row.names=FALSE, na = "")
write.csv(df, paste(gsub(".csv", "", file_path), "10k.csv", sep=""), row.names=FALSE, na = "")
require(tidyr)
require(dplyr)
require(ggplot2)
setwd("~/DataVisualization/DV_TProject1/01 Data")
file_path <- "StormEvents_details-ftp_v1.0_d2015_c2015102110k.csv"
df <- read.csv(file_path, stringsAsFactors = FALSE)
str(df)
measures <- c("BEGIN_YEARMONTH", "BEGIN_DAY", "BEGIN_TIME", "END_YEARMONTH", "END_DAY", "END_TIME", "EPISODE_ID", "EVENT_ID", "STATE_FIPS", "YEAR", "CZ_FIPS", "INJURIES_DIRECT", "INJURIES_INDIRECT", "DEATHS_DIRECT", "DEATHS_INDIRECT", "DAMAGE_PROPERTY", "DAMAGE_CROPS", "MAGNITUDE", "TOR_LENGTH", "TOR_WIDTH", "BEGIN_RANGE", "END_RANGE", "BEGIN_LAT", "BEGIN_LON", "END_LAT", "END_LON")
measures <- c("BEGIN_YEARMONTH", "BEGIN_DAY", "BEGIN_TIME", "END_YEARMONTH", "END_DAY", "END_TIME", "EPISODE_ID", "EVENT_ID", "STATE_FIPS", "YEAR", "CZ_FIPS", "INJURIES_DIRECT", "INJURIES_INDIRECT", "DEATHS_DIRECT", "DEATHS_INDIRECT", "DAMAGE_PROPERTY", "DAMAGE_CROPS", "MAGNITUDE", "TOR_LENGTH", "TOR_WIDTH", "BEGIN_RANGE", "END_RANGE", "BEGIN_LAT", "BEGIN_LON", "END_LAT", "END_LON")
if( length(measures) > 1 || ! is.na(measures)) {
for(m in measures) {
df[m] <- data.frame(lapply(df[m], gsub, pattern="[^--.0-9]",replacement= ""))
}
}
write.csv(df, paste(gsub(".csv", "", file_path), ".reformatted.csv", sep=""), row.names=FALSE, na = "")
dimensions <- setdiff(names(df), measures)
if( length(measures) > 1 || ! is.na(dimensions)) {
for(d in dimensions) {
# Get rid of " and ' in dimensions.
df[d] <- data.frame(lapply(df[d], gsub, pattern="[\"']",replacement= ""))
# Change & to and in dimensions.
df[d] <- data.frame(lapply(df[d], gsub, pattern="&",replacement= " and "))
# Change : to ; in dimensions.
df[d] <- data.frame(lapply(df[d], gsub, pattern=":",replacement= ";"))
}
}
write.csv(df, paste(gsub(".csv", "", file_path), ".reformatted.csv", sep=""), row.names=FALSE, na = "")
tableName <- gsub(" +", "_", gsub("[^A-z, 0-9, ]", "", gsub(".csv", "", file_path)))
sql <- paste("CREATE TABLE", tableName, "(\n-- Change table_name to the table name you want.\n")
if( length(measures) > 1 || ! is.na(dimensions)) {
for(d in dimensions) {
sql <- paste(sql, paste(d, "varchar2(4000),\n"))
}
}
if( length(measures) > 1 || ! is.na(measures)) {
for(m in measures) {
if(m != tail(measures, n=1)) sql <- paste(sql, paste(m, "number(38,4),\n"))
else sql <- paste(sql, paste(m, "number(38,4)\n"))
}
}
sql <- paste(sql, ");")
cat(sql)
setwd("~/DataVisualization/DV_TProject1/01 Data")
file_path <- "StormEvents_details-ftp_v1.0_d2015_c2015102110k.reformatted.csv"
df <- read.csv(file_path, stringsAsFactors = FALSE)
separate(df, BEGIN_TIME, c("H", "M"))
n = 13
n <- 13
b <- 10
13 % 10
13 %% 10
13 %/% 10
df %>% mutate(., BEGIN_MIN = BEGIN_TIME %% 100)
view(df)
require(tidyr)
require(dplyr)
head(select(df, BEGIN_TIME, BEGIN_MIN))
df <- df %>% mutate(., BEGIN_MIN = BEGIN_TIME %% 100)
df2 <- select(df, BEGIN_TIME, BEGIN_MIN)
head(df2)
df <- read.csv(file_path, stringsAsFactors = FALSE)
df <- df %>% mutate(., BEGIN_MIN = BEGIN_TIME %% 100, BEGIN_HOUR = BEGIN_TIME %/% 100)
df2 <- select(df, BEGIN_TIME, BEGIN_HOUR, BEGIN_MIN)
head(df2)
df2 <- df2 %>% mutate(., BEGIN_MIN = BEGIN_MIN / 60)
head(df2)
df2 <- df2 %>% mutate(., BEGIN_TIME = BEGIN_HOUR + BEGIN_TIME)
head(df2)
df2 <- df2 %>% mutate(., BEGIN_TIME = BEGIN_HOUR + BEGIN_MIN)
head(df2)
df <- read.csv(file_path, stringsAsFactors = FALSE)
df <- df %>% mutate(., BEGIN_MIN = BEGIN_TIME %% 100, BEGIN_HOUR = BEGIN_TIME %/% 100, BEGIN_MIN = BEGIN_MIN / 60, BEGIN_TIME = BEGIN_HOUR + BEGIN_MIN)
head(df2)
Head(select(df, BEGIN_TIME))
head(select(df, BEGIN_TIME))
head(df)
df <- df %>% mutate(., END_MIN = END_TIME %% 100, END_HOUR = END_TIME %/% 100, END_MIN = END_MIN / 60, END_TIME = END_HOUR + END_MIN)
head(select(df, BEGIN_TIME, END_TIME))
library(lubridate)
write.csv(df, paste(gsub(".csv", "", file_path), ".reformatted2.csv", sep=""), row.names=FALSE, na = "")
require(tidyr)
require(dplyr)
library(lubridate)
setwd("~/DataVisualization/DV_TProject1/01 Data")
file_path <- "StormEvents_details-ftp_v1.0_d2015_c2015102110k.reformatted2.csv"
df <- read.csv(file_path, stringsAsFactors = FALSE)
file_path <- "StormEvents_details-ftp_v1.0_d2015_c2015102110k.reformatted2.csv"
df <- read.csv(file_path, stringsAsFactors = FALSE)
head(select(df, BEGIN_TIME))
df2 <- df %>% select(., EVENT_TYPE, STATE, DAMAGE_CROPS, DAMAGE_PROPERTY, BEGIN_TIME, END_TIME)
head(df2)
df2 <- df %>% select(., EVENT_TYPE, STATE, DAMAGE_CROPS, DAMAGE_PROPERTY, BEGIN_TIME, END_TIME) %>% mutate(., DAMAGE_KPI = (DAMAGE_CROPS+ DAMAGE_PROPERTY) / (END_TIME - BEGIN_TIME))
head(df2)
df2 <- df %>% select(., EVENT_TYPE, STATE, DAMAGE_CROPS, DAMAGE_PROPERTY, BEGIN_TIME, END_TIME) %>% filter(., DAMAGE_CROPS != 0) %>% mutate(., DAMAGE_KPI = (DAMAGE_CROPS+ DAMAGE_PROPERTY) / (END_TIME - BEGIN_TIME))
head(df2)
df2 <- df %>% select(., EVENT_TYPE, STATE, DAMAGE_CROPS, DAMAGE_PROPERTY, BEGIN_TIME, END_TIME) %>% filter(., DAMAGE_CROPS != 0 | DAMAGE_PROPERTY != 0) %>% mutate(., DAMAGE_KPI = (DAMAGE_CROPS+ DAMAGE_PROPERTY) / (END_TIME - BEGIN_TIME))
head(df2)
df2 <- df %>% select(., EVENT_TYPE, STATE, DAMAGE_CROPS, DAMAGE_PROPERTY, BEGIN_TIME, END_TIME) %>% filter(., DAMAGE_CROPS != 0 | DAMAGE_PROPERTY != 0) %>% mutate(., DAMAGE_KPI = (DAMAGE_CROPS+ DAMAGE_PROPERTY) / (END_TIME - BEGIN_TIME)) %>% filter(., DAMAGE_KPI > 0)
head(df2)
ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_discrete() +
labs(title='Diamonds Crosstab\nSUM_PRICE, SUM_CARAT, SUM_PRICE / SUM_CARAT') +
labs(x=paste("COLOR"), y=paste("CLARITY")) +
layer(data=df2,
mapping=aes(x=EVENT_TYPE, y=STATE, label=DAMAGE_KPI),
stat="identity",
stat_params=list(),
geom="text",
geom_params=list(colour="black"),
position=position_identity()
)
ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_discrete() +
labs(title='Damage From Natural Disasters') +
labs(x=paste("COLOR"), y=paste("CLARITY")) +
layer(data=df2,
mapping=aes(x=EVENT_TYPE, y=STATE),
stat="identity",
stat_params=list(),
geom="text",
geom_params=list(colour=DAMAGE_KPI),
position=position_identity()
)
head(df2)
ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_discrete() +
labs(title='Damage From Natural Disasters') +
labs(x=paste("COLOR"), y=paste("CLARITY")) +
layer(data=df2,
mapping=aes(x=EVENT_TYPE, y=STATE, color = DAMAGE_KPI),
stat="identity",
stat_params=list(),
geom="text",
geom_params=list(colour="black"),
position=position_identity()
)
ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_discrete() +
labs(title='Damage From Natural Disasters') +
labs(x=paste("COLOR"), y=paste("CLARITY")) +
layer(data=df2,
mapping=aes(x=EVENT_TYPE, y=STATE, color = DAMAGE_KPI),
stat="identity",
stat_params=list(),
geom="tile",
geom_params=list(colour="black"),
position=position_identity()
)
ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_discrete() +
labs(title='Damage From Natural Disasters') +
labs(x=paste("COLOR"), y=paste("CLARITY")) +
layer(data=df2,
mapping=aes(x=EVENT_TYPE, y=STATE, fill = DAMAGE_KPI),
stat="identity",
stat_params=list(),
geom="tile",
geom_params=list(),
position=position_identity()
)
df2 <- df %>% select(., EVENT_TYPE, STATE, DAMAGE_CROPS, DAMAGE_PROPERTY, BEGIN_TIME, END_TIME) %>% filter(., DAMAGE_CROPS != 0 | DAMAGE_PROPERTY != 0) %>% mutate(., DAMAGE_KPI = (DAMAGE_CROPS+ DAMAGE_PROPERTY) / (END_TIME - BEGIN_TIME)) %>% filter(., DAMAGE_KPI > 500)
ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_discrete() +
labs(title='Damage From Natural Disasters') +
labs(x=paste("COLOR"), y=paste("CLARITY")) +
layer(data=df2,
mapping=aes(x=EVENT_TYPE, y=STATE, fill = DAMAGE_KPI),
stat="identity",
stat_params=list(),
geom="tile",
geom_params=list(),
position=position_identity()
)
measures <- c("BEGIN_YEARMONTH", "BEGIN_DAY", "BEGIN_TIME", "END_YEARMONTH", "END_DAY", "END_TIME", "EPISODE_ID", "EVENT_ID", "STATE_FIPS", "YEAR", "CZ_FIPS", "INJURIES_DIRECT", "INJURIES_INDIRECT", "DEATHS_DIRECT", "DEATHS_INDIRECT", "DAMAGE_PROPERTY", "DAMAGE_CROPS", "MAGNITUDE", "TOR_LENGTH", "TOR_WIDTH", "BEGIN_RANGE", "END_RANGE", "BEGIN_LAT", "BEGIN_LON", "END_LAT", "END_LON", "BEGIN_HOUR", "BEGIN_MIN", "END_MIN", "END_HOUR")
dimensions <- setdiff(names(df), measures)
library(lubridate)
require(tidyr)
require(dplyr)
require(ggplot2)
setwd("~/DataVisualization/DV_TProject1/01 Data")
file_path <- "StormEvents_details-ftp_v1.0_d2015_c2015102110k.reformatted2.csv"
df <- read.csv(file_path, stringsAsFactors = FALSE)
dimensions <- setdiff(names(df), measures)
tableName <- gsub(" +", "_", gsub("[^A-z, 0-9, ]", "", gsub(".csv", "", file_path)))
sql <- paste("CREATE TABLE", tableName, "(\n-- Change table_name to the table name you want.\n")
if( length(measures) > 1 || ! is.na(dimensions)) {
for(d in dimensions) {
sql <- paste(sql, paste(d, "varchar2(4000),\n"))
}
}
if( length(measures) > 1 || ! is.na(measures)) {
for(m in measures) {
if(m != tail(measures, n=1)) sql <- paste(sql, paste(m, "number(38,4),\n"))
else sql <- paste(sql, paste(m, "number(38,4)\n"))
}
}
sql <- paste(sql, ");")
cat(sql)
#CrosstabWorkflow
require(tidyr)
require(ggplot2)
require(dplyr)
library(lubridate)
require("jsonlite")
require("RCurl")
setwd("~/DataVisualization/DV_TProject1/01 Data")
file_path <- "StormEvents_details-ftp_v1.0_d2015_c2015102110k.reformatted2.csv"
#df <- read.csv(file_path, stringsAsFactors = FALSE)
df <- data.frame(fromJSON(getURL(URLencode('skipper.cs.utexas.edu:5001/rest/native/?query="select * from STORMEVENTS"'),httpheader=c(DB='jdbc:oracle:thin:@sayonara.microlab.cs.utexas.edu:1521:orcl', USER='C##cs329e_apb766', PASS='orcl_apb766', MODE='native_mode', MODEL='model', returnDimensions = 'False', returnFor = 'JSON'), verbose = TRUE), ))
RegDF <- data.frame(fromJSON(getURL(URLencode('skipper.cs.utexas.edu:5001/rest/native/?query="select * from STATEREGION"'),httpheader=c(DB='jdbc:oracle:thin:@sayonara.microlab.cs.utexas.edu:1521:orcl', USER='C##cs329e_apb766', PASS='orcl_apb766', MODE='native_mode', MODEL='model', returnDimensions = 'False', returnFor = 'JSON'), verbose = TRUE), ))
head(df)
df2 <- df %>% select(., EVENT_TYPE, STATE, DAMAGE_CROPS, DAMAGE_PROPERTY, BEGIN_TIME, END_TIME) %>% mutate(DAMAGE_CROPS = strtoi(DAMAGE_CROPS), DAMAGE_PROPERTY = strtoi(DAMAGE_PROPERTY)) %>% filter(., DAMAGE_CROPS > 1 | DAMAGE_PROPERTY > 1) %>% filter(., DAMAGE_CROPS != "null" & DAMAGE_PROPERTY != "null") %>% mutate(., DAMAGE_KPI = (as.numeric(DAMAGE_CROPS) + as.numeric(DAMAGE_PROPERTY)) / (as.numeric(END_TIME) - as.numeric(BEGIN_TIME))) %>% filter(., DAMAGE_KPI > 80 & DAMAGE_KPI != Inf) %>% arrange(STATE) %>% distinct()
View(df2)
df3 <- df2 %>% group_by(., EVENT_TYPE, STATE) %>% mutate(KPI = cumsum(DAMAGE_KPI)) %>% mutate(MAX = max(KPI)) %>% select(EVENT_TYPE, STATE, MAX) %>% distinct()
View(df3)
df3 <- left_join(df3, RegDF, by = "STATE")
head(df2)
ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_discrete() +
scale_fill_gradient2(low="white", mid = "red", high= "darkred", midpoint = 7500) +
labs(title='Damage From Natural Disasters') +
labs(x=paste("Disaster"), y=paste("State")) +
layer(data=df3,
mapping=aes(x=EVENT_TYPE, y=REGION, fill = MAX),
stat="identity",
stat_params=list(),
geom="tile",
geom_params=list(),
position=position_identity()
)
#CrosstabWorkflow
require(tidyr)
require(dplyr)
library(lubridate)
require(ggplot2)
require(gridExtra)
require(jsonlite)
require(RCurl)
dfs <- data.frame(fromJSON(getURL(URLencode('skipper.cs.utexas.edu:5001/rest/native/?query="select EVENT_TYPE, DAMAGE_CROPS, DAMAGE_PROPERTY, END_TIME, BEGIN_TIME from STORMEVENTS where DAMAGE_CROPS is not null and DAMAGE_PROPERTY is not null"'),httpheader=c(DB='jdbc:oracle:thin:@sayonara.microlab.cs.utexas.edu:1521:orcl', USER='C##cs329e_jdg3666', PASS='orcl_jdg3666', MODE='native_mode', MODEL='model', returnDimensions = 'False', returnFor = 'JSON'), verbose = TRUE), ))
dfnew <- dfs %>% select(EVENT_TYPE, DAMAGE_CROPS, DAMAGE_PROPERTY, END_TIME, BEGIN_TIME) %>% filter(DAMAGE_PROPERTY > 0, DAMAGE_CROPS > 0) %>% mutate (TOTAL_TIME = (abs(END_TIME - BEGIN_TIME)) / 100) %>% filter(TOTAL_TIME > 0)
head(dfnew)
require(extrafont)
crop <- ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_continuous() +
labs(title='Crop and Property Damage across Disasters less than 24 hours') +
labs(x="Total Time of Disaster", y=paste("Crop Damage")) +
layer(data=dfnew,
mapping=aes(as.numeric(TOTAL_TIME), y=as.numeric(as.character(DAMAGE_CROPS)), color=EVENT_TYPE),
stat="identity",
stat_params=list(),
geom="point",
geom_params=list(),
#position=position_identity()
position=position_jitter(width=0.3, height=0)
)
property <- ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_continuous() +
labs(title='Crop and Property Damage across Disasters less than 24 hours') +
labs(x="Total Time of Disaster", y=paste("Crop Damage")) +
layer(data=dfnew,
mapping=aes(as.numeric(TOTAL_TIME), y=as.numeric(as.character(DAMAGE_PROPERTY)), color=EVENT_TYPE),
stat="identity",
stat_params=list(),
geom="point",
geom_params=list(),
#position=position_identity()
position=position_jitter(width=0.3, height=0)
)
grid.arrange(crop, property)
#CrosstabWorkflow
require(tidyr)
require(dplyr)
library(lubridate)
require(ggplot2)
require(gridExtra)
require(jsonlite)
require(RCurl)
dfs <- data.frame(fromJSON(getURL(URLencode('skipper.cs.utexas.edu:5001/rest/native/?query="select EVENT_TYPE, DAMAGE_CROPS, DAMAGE_PROPERTY, END_TIME, BEGIN_TIME from STORMEVENTS where DAMAGE_CROPS is not null and DAMAGE_PROPERTY is not null"'),httpheader=c(DB='jdbc:oracle:thin:@sayonara.microlab.cs.utexas.edu:1521:orcl', USER='C##cs329e_jdg3666', PASS='orcl_jdg3666', MODE='native_mode', MODEL='model', returnDimensions = 'False', returnFor = 'JSON'), verbose = TRUE), ))
dfnew <- dfs %>% select(EVENT_TYPE, DAMAGE_CROPS, DAMAGE_PROPERTY, END_TIME, BEGIN_TIME) %>% filter(DAMAGE_PROPERTY > 0, DAMAGE_CROPS > 0) %>% mutate (TOTAL_TIME = (abs(END_TIME - BEGIN_TIME)) / 100) %>% filter(TOTAL_TIME > 0)
head(dfnew)
require(extrafont)
crop <- ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_continuous() +
labs(title='Crop and Property Damage across Disasters less than 24 hours') +
labs(x="Total Time of Disaster", y=paste("Crop Damage")) +
layer(data=dfnew,
mapping=aes(as.numeric(TOTAL_TIME), y=as.numeric(as.character(DAMAGE_CROPS)), color=EVENT_TYPE),
stat="identity",
stat_params=list(),
geom="point",
geom_params=list(),
#position=position_identity()
position=position_jitter(width=0.3, height=0)
)
property <- ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_continuous() +
labs(title='Crop and Property Damage across Disasters less than 24 hours') +
labs(x="Total Time of Disaster", y=paste("Crop Damage")) +
layer(data=dfnew,
mapping=aes(as.numeric(TOTAL_TIME), y=as.numeric(as.character(DAMAGE_PROPERTY)), color=EVENT_TYPE),
stat="identity",
stat_params=list(),
geom="point",
geom_params=list(),
#position=position_identity()
position=position_jitter(width=0.3, height=0)
)
#grid.arrange(crop, property)
install.packages("gridExtra")
#CrosstabWorkflow
require(tidyr)
require(dplyr)
library(lubridate)
require(ggplot2)
require(gridExtra)
require(jsonlite)
require(RCurl)
dfs <- data.frame(fromJSON(getURL(URLencode('skipper.cs.utexas.edu:5001/rest/native/?query="select EVENT_TYPE, DAMAGE_CROPS, DAMAGE_PROPERTY, END_TIME, BEGIN_TIME from STORMEVENTS where DAMAGE_CROPS is not null and DAMAGE_PROPERTY is not null"'),httpheader=c(DB='jdbc:oracle:thin:@sayonara.microlab.cs.utexas.edu:1521:orcl', USER='C##cs329e_jdg3666', PASS='orcl_jdg3666', MODE='native_mode', MODEL='model', returnDimensions = 'False', returnFor = 'JSON'), verbose = TRUE), ))
dfnew <- dfs %>% select(EVENT_TYPE, DAMAGE_CROPS, DAMAGE_PROPERTY, END_TIME, BEGIN_TIME) %>% filter(DAMAGE_PROPERTY > 0, DAMAGE_CROPS > 0) %>% mutate (TOTAL_TIME = (abs(END_TIME - BEGIN_TIME)) / 100) %>% filter(TOTAL_TIME > 0)
head(dfnew)
require(extrafont)
crop <- ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_continuous() +
labs(title='Crop and Property Damage across Disasters less than 24 hours') +
labs(x="Total Time of Disaster", y=paste("Crop Damage")) +
layer(data=dfnew,
mapping=aes(as.numeric(TOTAL_TIME), y=as.numeric(as.character(DAMAGE_CROPS)), color=EVENT_TYPE),
stat="identity",
stat_params=list(),
geom="point",
geom_params=list(),
#position=position_identity()
position=position_jitter(width=0.3, height=0)
)
property <- ggplot() +
coord_cartesian() +
scale_x_discrete() +
scale_y_continuous() +
labs(title='Crop and Property Damage across Disasters less than 24 hours') +
labs(x="Total Time of Disaster", y=paste("Crop Damage")) +
layer(data=dfnew,
mapping=aes(as.numeric(TOTAL_TIME), y=as.numeric(as.character(DAMAGE_PROPERTY)), color=EVENT_TYPE),
stat="identity",
stat_params=list(),
geom="point",
geom_params=list(),
#position=position_identity()
position=position_jitter(width=0.3, height=0)
)
grid.arrange(crop, property)
